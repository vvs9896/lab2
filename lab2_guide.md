# <div align="center"> Продолжаем разворачивать


## <div align="center"> Intro 

В прошлой лабораторной работе мы поняли что такое контейнер, откуда его брать и как запускать. Теперь задача несколько сложнее - научиться запускать несколько контейнеров за раз так, чтобы они могли друг с другом коммуницировать.

В репозитории приведена система из 3 контейнеров:
- producer1
- producer2
- consumer

Producer-ы - контейнеры, которые производят данные. Условная эмуляция каких-нибудь датчиков ~~(по заветам В. Г. Иваненко)~~, которые измеряют данные в реальном времени и отправляют их на сервер. У сервера же стоит невероятно сложная вычислительная задача - перемножить 2 матрицы (данные для которых и отсылают producer-ы).

Рассмотрим эти програмы поподробнее.

**producer.go** использует стандартную библиотеку http для отправки POST запросов на сервер. Если с Go вы столкнулись впервые, то в папке dev есть почти аналогичная программа на более распространённом языке python.

Фактически алгоритм заключается в следующем:
- сформировать запрос из типа producer-а и случайного числа
- отправить его на сервер
- проверить, не произошла ли ошибка при отправке и что сервер корректо её обработал
- после отправки всех сообщений, послать сообщение об окончании отправки

**consumer.cpp** использует микрофреймворк Crow, чтобы обрабатывать запросы. С++ нам знаком, а по фреймворку есть [подробный мануал на официальном сайте](https://crowcpp.org/master/). 

Алгоритм обработчика ещё проще:
- пока не пришло сообщение об окончании отправки, принимаем и записываем в память.
- пришло сообщение об окончании - обрабатываем данные.

Остальные файлы - необходимые .h для Crow и Dockerfile для запуска каждого из перечисленных выше приложений.

#### Это мы уже видели:
- consumer/Dockerfile
- producer1/Dockerfile
- producer2/Dockerfile

Для .cpp использум Debian за основу. Для .go официальные образы Go.

Каждый из контейнеров мы можем запустить отдельно. Как это сделать, объяснялось в первой лабораторной. Только для контейнеров producer необходимо указывать переменную окружения MSize: **sudo docker run -e MSize=10 producer**. (Контейнер был собран с именем producer)

А вот **docker-compose.yaml** - что-то новое.

## <div align="center"> docker compose 

Docker Compose (**DC** далее в гайде) - это инструмент, который позволяет определять и управлять многоконтейнерными приложениями в Docker. Он использует файл формата YAML для настройки сервисов, сетей и томов, необходимых для вашего приложения. С помощью Docker Compose вы можете определить связи между различными контейнерами и легко управлять их конфигурацией и развертыванием.

Используя Docker Compose, вы можете определить сервисы, сети и тома вашего приложения в едином файле, что упрощает управление и развертывание приложения в различных средах. Он предоставляет простой декларативный синтаксис для определения инфраструктуры вашего приложения, что упрощает сотрудничество с другими разработчиками.

Продробно про **DC** можно прочесть на [официальном сайте](https://docs.docker.com/compose/).

Docker compose файл начинается со строчки **version**. Она отвечает за версию синтаксиса. **V1** - устаревшая и больше не поддерживается.

version: '3' - указывает версию Docker Compose, используемую в файле.

Далее структура иерархическая:
- servies: # начало секции, где определяются сервисы (контейнеры) для запуска.
  - producer1: # имя сервиса (контейнера) producer1.
    - build: # определяет настройки для сборки контейнера.
      - context: # указывает путь к директории с Dockerfile для сборки контейнера.
      - no_cache: true # отключает кэширование при сборке контейнера producer1.
    - env_file: # указывает файлы с переменными окружения, которые будут загружены в контейнер producer1. 
    - networks: # определяет сети, к которым будет присоединен контейнер producer1.
  -
  -
    - resources: # определяет ресурсы, выделенные для контейнера consumer.
      - limits: - определяет ограничения ресурсов, в данном случае, CPU.
- networks: # начало секции, где определяются сети, используемые в приложении.
  - lab2network: # имя сети, в данном случае, lab2network.

Для запуска используется команда **docker compose up**.

**Размеры матриц указываются в файле MSize.env**

## <div align="center"> суть работы

После выполнения команды, вы должы увидеть в терминале сообщения от producer-ов об отправке сообщений. В какой-то момент темп отправки сильно упадёт, могут появится ошибки подключения к consumer-у. 

Задача лабораторной - изучить методики вертикального и горизонтального масштабирования.

**Вертикальное масштабирование** (также известное как масштабирование "по вертикали" или "вверх") предполагает увеличение мощности и ресурсов одного сервера или узла в системе. Это может включать увеличение объема оперативной памяти, процессорных ядер или пропускной способности сети. При вертикальном масштабировании система становится более мощной, но она все еще работает на одном сервере или узле.

**Горизонтальное масштабирование** (также известное как масштабирование "по горизонтали" или "в сторону") предполагает добавление дополнительных серверов или узлов в систему. Это позволяет распределить нагрузку между несколькими серверами и обеспечить более высокую производительность и доступность системы. Горизонтальное масштабирование обычно является более гибким и масштабируемым подходом, так как позволяет добавлять или удалять серверы по мере необходимости.

### <div align="center"> вертикальное масштабирование

Начнём исследование с вертикального масштабирования. Т.к. изменять ресурсы сервера аппаратно во время выполнения лабораторной работы, есть возможность не у всех, ограничимся программным ограничением производительности.

В **docker-compose.yaml** есть параметр, отвечающий за ограничение использования CPU consumer-ом.

Необходимо провести исследование времени общей работы многоконтейнерного приложения (от начала отправки сообщений до завершения вычислений сервером) при различных CPU ограничениях.

Скорее всего, вы обратите внимание на то, что хоть время и работы и сокращается, но ошибки доступа к серверу не исчезают.

---

Подводя итоги вертикального масштабирования:
- Самый простой метод увеличения производительности.
- Начиная с определенного момента, рост цен на комплектующие становится очень быстрым по сравнению с ростом их производительности. Это означает, что стоимость комплектующих значительно увеличивается, но при этом их производительность не увеличивается таким же темпом.
- Есть предел масштабирования (самый мощный на данный момент процессор с максимальным возможным для него объёмом памяти).
- Вертикальное масштабирование не может решить все архитектурные проблемы приложения. (В нашем случае Crow не может обрабатывать столько запросов, независимо от выделяемых процессорных ресурсов).

### <div align="center"> горизонтальное масштабирование

Обычно для горизонтального масштабирования используется дополнительный сервер - балансировщик нагрузки (**load balancer**). Практически все популярные прокси имеют такую возможность, но в данной лабораторной работе предлагается использовать **nginx** для решения этой задачи. 

В **docker-compose.yaml** закомментирован сервис **nginx**. С volumes мы ознакомились в прошлой лабораторной работе. **depends_on** означает, что данный сервис зависит от некоторых других (будет разворачиваться только после того, как развернутся сервисы, указанные в этом блоке).

Необходимо "сбалансировать нагрузку" от двух producer-ов на несколько контейнеров consumer-ов. Таким образом, чтобы результат работы на одном consumer-e и на нескольких был идентичен. 

Т.е. запросы от всех producer-ов идут в nginx, который в свою очередь распределяет задачи между consumer-ами.

Для объединения результатов необходимо отправлять через nginx в дополнительный скрипт, который объединит результаты.

## <div align="center">  Часть для самостоятельного ознакомления

- Docker networks
- Развёртывание nginx
- Методы балансировки нагрузки
